{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNmB2Jr8rYdkBB0NHFLRO7M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup"],"metadata":{"id":"SHqWsCtjCktR","executionInfo":{"status":"ok","timestamp":1721846355531,"user_tz":-540,"elapsed":817,"user":{"displayName":"김세희","userId":"11914523790363729060"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8Yut8fEv_L7v","executionInfo":{"status":"ok","timestamp":1721846396336,"user_tz":-540,"elapsed":334,"user":{"displayName":"김세희","userId":"11914523790363729060"}}},"outputs":[],"source":["import torch\n","from sklearn.preprocessing import LabelEncoder\n","\n","# 간단한 데이터 예시\n","question_encoder = LabelEncoder()\n","answer_encoder = LabelEncoder()\n","question_encoder.fit(['오늘 날씨 어때?', '날씨 알려줘', '날씨는?', '내일 날씨는?', '오늘 비 오나?'])\n","answer_encoder.fit(['오늘의 날씨는 맑습니다.', '오늘의 날씨는 흐립니다.', '오늘의 날씨는 비가 옵니다.', '내일은 구름 많습니다.', '오늘 비가 옵니다.'])\n","\n","def encode_sentence(sentence, encoder):\n","    tokens = sentence.split()  # 간단한 토큰화\n","    encoded_tokens = [encoder.transform([token])[0] for token in tokens if token in encoder.classes_]\n","    return torch.tensor(encoded_tokens, dtype=torch.long).unsqueeze(1)  # (seq_len, batch_size)\n","\n","def decode_sentence(encoded_sentence, decoder):\n","    tokens = encoded_sentence.squeeze().tolist()\n","    return ' '.join(decoder.inverse_transform(tokens))\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class TransformerChatBot(nn.Module):\n","    def __init__(self, vocab_size, embed_size, num_heads, num_layers, hidden_dim):\n","        super(TransformerChatBot, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embed_size)\n","        self.transformer = nn.Transformer(\n","            d_model=embed_size,\n","            nhead=num_heads,\n","            num_encoder_layers=num_layers,\n","            num_decoder_layers=num_layers\n","        )\n","        self.fc_out = nn.Linear(embed_size, vocab_size)\n","\n","    def forward(self, src, tgt):\n","        src_emb = self.embedding(src)\n","        tgt_emb = self.embedding(tgt)\n","        output = self.transformer(src_emb, tgt_emb)\n","        return self.fc_out(output)\n","\n","# 모델 초기화\n","vocab_size = len(question_encoder.classes_)  # 어휘 크기\n","embed_size = 128\n","num_heads = 8\n","num_layers = 2\n","hidden_dim = 256\n","\n","model = TransformerChatBot(vocab_size, embed_size, num_heads, num_layers, hidden_dim)\n","model.eval()  # 모델을 평가 모드로 전환\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hg4yZGsw_ST4","executionInfo":{"status":"ok","timestamp":1721846398673,"user_tz":-540,"elapsed":347,"user":{"displayName":"김세희","userId":"11914523790363729060"}},"outputId":"165ae25d-5da7-4b21-9bf5-d85d06368bba"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"output_type":"execute_result","data":{"text/plain":["TransformerChatBot(\n","  (embedding): Embedding(5, 128)\n","  (transformer): Transformer(\n","    (encoder): TransformerEncoder(\n","      (layers): ModuleList(\n","        (0-1): 2 x TransformerEncoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","          )\n","          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","    (decoder): TransformerDecoder(\n","      (layers): ModuleList(\n","        (0-1): 2 x TransformerDecoderLayer(\n","          (self_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","          )\n","          (multihead_attn): MultiheadAttention(\n","            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n","          )\n","          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n","          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","          (dropout1): Dropout(p=0.1, inplace=False)\n","          (dropout2): Dropout(p=0.1, inplace=False)\n","          (dropout3): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (fc_out): Linear(in_features=128, out_features=5, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import torch\n","\n","# 대화 기록 초기화\n","messages = []\n","\n","def generate_response(user_input):\n","    # 사용자 입력을 인코딩\n","    user_input_encoded = encode_sentence(user_input, question_encoder)\n","\n","    # Transformer 모델을 사용하여 응답 생성 (임시로 랜덤 응답)\n","    # 실제로는 모델을 학습시켜야 합니다.\n","    response_encoded = torch.randint(0, vocab_size, (user_input_encoded.size(0), 1))  # 임시 응답\n","    reply = decode_sentence(response_encoded, answer_encoder)\n","\n","    return reply\n","\n","while True:\n","    message = input(\"User: \")\n","    if message:\n","        messages.append({\"role\": \"user\", \"content\": message})\n","\n","        # 모델을 사용하여 응답 생성\n","        reply = generate_response(message)\n","\n","        # 응답 출력 및 기록\n","        print(f\"AIUS: {reply}\")\n","        messages.append({\"role\": \"assistant\", \"content\": reply})\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGTZMnck_WcD","outputId":"cf9cc7f3-4eac-4ba8-908d-16738e3ed667"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["User: 날씨 알려줘\n","AIUS: \n"]}]}]}