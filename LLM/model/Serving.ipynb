{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907b6db-461f-4430-a3e3-844bf1403337",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-chroma\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-index\n",
    "!pip install transformers einops accelerate langchain bitsandbytes\n",
    "!pip install sentence_transformers #Embedding\n",
    "!pip install llama_index\n",
    "!pip install llama-index-embeddings-langchain\n",
    "!pip install llama-index-llms-huggingface\n",
    "%pip install llama-index\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "%pip install llama-index-embeddings-instructor\n",
    "!pip install chromadb\n",
    "%pip install llama-index-vector-stores-chroma\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-index\n",
    "%pip install llama-index-retrievers-bm25\n",
    "!pip install KoNLPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb7fba-f601-4426-9123-839d8ba51ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core import PromptTemplate\n",
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from konlpy.tag import Okt  # konlpy의 Okt 형태소 분석기 import\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "import chromadb\n",
    "import nest_asyncio\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "\n",
    "# Define a directory to persist index data\n",
    "PERSIST_DIR = \"./storage\"\n",
    "\n",
    "# 한국어 불용어 리스트\n",
    "korean_stopwords = ['이', '그', '저', '있다', '하다', '것', '들', '때', '등', '에서']\n",
    "\n",
    "        # konlpy 기반의 Okt 토크나이저를 활용하여 텍스트를 한국어로 처리하는 BM25 리트리버 설정\n",
    "class KonlpyTokenizer:\n",
    "    def __init__(self):\n",
    "        self.tokenizer = Okt()\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        # konlpy의 morphs 함수를 사용하여 형태소 단위로 토큰화\n",
    "        tokens = self.tokenizer.morphs(text)\n",
    "        # 불용어 제거\n",
    "        tokens = [token for token in tokens if token not in korean_stopwords]\n",
    "        return tokens\n",
    "\n",
    "\n",
    "class RAGService:\n",
    "    def __init__(self):\n",
    "        ###MODEL 구축##################\n",
    "        system_prompt=\"\"\"\n",
    "        <|SYSTEM|>#         \n",
    "        당신은 경북대학교 정보 안내 챗봇으로, 질문에 대한 답을 해주어야합니다.\n",
    "        Casual Answer로 답변 형식을 지정합니다.\n",
    "        당신은 학습된 내용 안에서 질문에 답변해야합니다.\n",
    "        학습된 내용이 없을 경우에는, 연결된 DB내용을 참조하도록 합니다.\n",
    "        학습된 내용은 datasets항목 안에 있는 것을 뜻하며,\n",
    "        DB 연결은 아직 하지 않아, DB를 참조할 경우 \"내용을 찾지 못했습니다.\"라고 답하여야합니다.\n",
    "        당신은 스스로 답변 가치를 생성할 수 있습니다.\n",
    "        null이나 빈 값은 반환하지 않습니다.\n",
    "        url 반환 시, <SYSTEM>을 붙이지 않습니다.\n",
    "\n",
    "        Question: 크누큐브 사이트 알려줘\n",
    "        Answer: https://knucube.knu.ac.kr/\n",
    "\n",
    "        Question: 국어국문학과 전공 커리큘럼 사이트를 알려줘\n",
    "        Answer: https://home.knu.ac.kr/HOME/knujob/sub.htm?nav_code=knu1668399325&code=dept1&dept=dept-korean\n",
    "        \"\"\"\n",
    "        # This will wrap the default prompts that are internal to llama-index\n",
    "        query_wrapper_prompt = PromptTemplate(\"<|USER|>{query_str}<|ASSISTANT|>\")\n",
    "\n",
    "        model= HuggingFaceLLM(\n",
    "            context_window=2048,\n",
    "            max_new_tokens=256,\n",
    "            generate_kwargs={\"temperature\": 0.25, \"do_sample\": False},\n",
    "            system_prompt=system_prompt,\n",
    "            query_wrapper_prompt=query_wrapper_prompt,\n",
    "            tokenizer_name=\"Dansoeun/Llama3-owen-Ko-3-8B-Dansoeun\",\n",
    "            model_name=\"Dansoeun/Llama3-owen-Ko-3-8B-Dansoeun\",\n",
    "            device_map=\"auto\",\n",
    "            tokenizer_kwargs={\"max_length\": 2048},\n",
    "            # uncomment this if using CUDA to reduce memory usage\n",
    "            # model_kwargs={\"torch_dtype\": torch.float16}\n",
    "        )\n",
    "        embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "        \n",
    "        Settings.llm=model\n",
    "        Settings.embed_model=embed_model\n",
    "        Settings.chunk_size = 512\n",
    "        ########RAG##########################\n",
    "        # load documents\n",
    "        documents = SimpleDirectoryReader(\"txt_db\").load_data()\n",
    "        \n",
    "        # initialize node parser\n",
    "        splitter = SentenceSplitter(chunk_size=512)\n",
    "        \n",
    "        nodes = splitter.get_nodes_from_documents(documents)\n",
    "\n",
    "        konlpytokenizer=KonlpyTokenizer()\n",
    "        \n",
    "        # Korean BM25 retriever\n",
    "        bm25_retriever = BM25Retriever.from_defaults(\n",
    "            nodes=nodes,\n",
    "            similarity_top_k=2,\n",
    "            stemmer=None,  # PyStemmer 대신 직접 토크나이저에서 처리\n",
    "            language=None,  # 언어 기본 처리를 비활성화\n",
    "            tokenizer=KonlpyTokenizer(),  # konlpy 기반의 토크나이저\n",
    "        )\n",
    "        \n",
    "        bm25_retriever.persist(\"./bm25_retriever\")\n",
    "        loaded_bm25_retriever = BM25Retriever.from_persist_dir(\"./bm25_retriever\")\n",
    "\n",
    "        docstore = SimpleDocumentStore()\n",
    "        docstore.add_documents(nodes)\n",
    "        \n",
    "        db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "        chroma_collection = db.get_or_create_collection(\"dense_vectors\")\n",
    "        vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "        \n",
    "        storage_context = StorageContext.from_defaults(\n",
    "            docstore=docstore, vector_store=vector_store\n",
    "        )\n",
    "        \n",
    "        #index = VectorStoreIndex(nodes=nodes, storage_context=storage_context)\n",
    "        self.index=VectorStoreIndex(nodes=nodes, storage_context=storage_context)\n",
    "        #nest_asyncio.apply()\n",
    "\n",
    "        self.retriever = QueryFusionRetriever(\n",
    "            [\n",
    "                self.index.as_retriever(similarity_top_k=2),\n",
    "                BM25Retriever.from_defaults(\n",
    "                    docstore=self.index.docstore, similarity_top_k=2\n",
    "                ),\n",
    "            ],\n",
    "            num_queries=1,\n",
    "            use_async=True,\n",
    "        )\n",
    "    def query(self, query: str) -> str:\n",
    "        query_engine = RetrieverQueryEngine(self.retriever)  \n",
    "        response = query_engine.query(query)\n",
    "        return str(response)\n",
    "\n",
    "        \n",
    "\n",
    "rag_service=RAGService()\n",
    "       \n",
    "query_result=rag_service.query(\"경북대 컴학 알려줘 \")\n",
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0ca96-ec05-4596-aa06-ecd380d23a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
